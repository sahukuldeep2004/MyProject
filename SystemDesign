https://www.designgurus.io/blog/high-availability-system-design-basics
No matter your programming language, start by understanding the basics of how systems are designed.

👍 𝐒𝐲𝐬𝐭𝐞𝐦 𝐃𝐞𝐬𝐢𝐠𝐧 𝐊𝐞𝐲 𝐂𝐨𝐧𝐜𝐞𝐩𝐭𝐬
1. Scalability: https://lnkd.in/gpge_z76
Scalability is the property of a system to handle a growing amount of load by adding resources to the system.
Vertical Scaling (Scale up):-This means adding more power to your existing machines by upgrading server with more RAM, faster CPUs, or additional storage.
Horizontal Scaling (Scale out):-This means adding more machines to your system to spread the workload across multiple servers
2. Latency vs Throughput: https://lnkd.in/g_amhAtN
Latency is the delay in network communication. It shows the time that data takes to transfer across the network. Networks with a longer delay or lag 
have high latency, while those with fast response times have lower latency. In contrast, throughput refers to the average volume of data that can 
actually pass through the network over a specific time. It indicates the number of data packets that arrive at their destinations successfully and the 
data packet loss.
Best : high throughput * low latency
Throughput can be measured in MBps and latency in milliseconds.
Throughput is imapcted by Bandwidth, network processing power, packet loss, and network topology and Latency is impacted by Geographical distances, 
network congestion, transport protocol, and network infrastructure. 
3. CAP Theorem: https://lnkd.in/g3hmVamx
4. ACID Transactions: https://lnkd.in/gMe2JqaF
5. Rate Limiting: https://lnkd.in/gWsTDR3m
6. API Design: https://lnkd.in/ghYzrr8q
7. Strong vs Eventual Consistency: https://lnkd.in/gJ-uXQXZ
8. Distributed Tracing: https://lnkd.in/d6r5RdXG
9. Synchronous vs. asynchronous communications: https://lnkd.in/gC3F2nvr
10. Batch Processing vs Stream Processing: https://lnkd.in/g4_MzM4s
11. Fault Tolerance: https://lnkd.in/dVJ6n3wA

👍 𝐒𝐲𝐬𝐭𝐞𝐦 𝐃𝐞𝐬𝐢𝐠𝐧 𝐁𝐮𝐢𝐥𝐝𝐢𝐧𝐠 𝐁𝐥𝐨𝐜𝐤𝐬
1. Databases: https://lnkd.in/gti8gjpz
2. Horizontal vs Vertical Scaling: https://lnkd.in/gAH2e9du
3. Caching: https://lnkd.in/gC9piQbJ
4. Distributed Caching: https://lnkd.in/g7WKydNg
5. Load Balancing: https://lnkd.in/gQaa8sXK
6. SQL vs NoSQL: https://lnkd.in/g3WC_yxn
7. Database Scaling: https://lnkd.in/gAXpSyWQ
8. Data Replication: https://lnkd.in/gVAJxTpS
9. Data Redundancy: https://lnkd.in/gNN7TF7n
10. Database Sharding: https://lnkd.in/gMqqc6x9
11. Database Index's: https://lnkd.in/gCeshYVt
12. Proxy Server: https://lnkd.in/gi8KnKS6
13. WebSocket: https://lnkd.in/g76Gv2KQ
14. API Gateway: https://lnkd.in/gnsJGJaM
15. Message Queues: https://lnkd.in/gTzY6uk8

👍 𝐒𝐲𝐬𝐭𝐞𝐦 𝐃𝐞𝐬𝐢𝐠𝐧 𝐀𝐫𝐜𝐡𝐢𝐭𝐞𝐜𝐭𝐮𝐫𝐚𝐥 𝐏𝐚𝐭𝐭𝐞𝐫𝐧𝐬
1. Event-Driven Architecture: https://lnkd.in/dp8CPvey 
2. Client-Server Architecture: https://lnkd.in/dAARQYzq
3. Serverless Architecture: https://lnkd.in/gQNAXKkb
4. Microservices Architecture: https://lnkd.in/gFXUrz_T

➤ 𝗕𝗮𝘀𝗶𝗰𝘀 𝗼𝗳 𝗦𝘆𝘀𝘁𝗲𝗺 𝗗𝗲𝘀𝗶𝗴𝗻
 • What is System Design?
 • Functional vs Non Functional Requirements
 • What are the components of System Design?
 • System Design Life Cycle | SDLC (Design)
 • Structured Analysis and Structured Design
 • System Design Strategy
 • Database Sharding - Concept
 • Horizontal and Vertical Scaling
 • Load Balancer in System Design
 • Routing requests through Load Balancer
 • Latency and Throughput in System Design
 • Object-Oriented Analysis and Design
 • Difference between Structured and Object-Oriented Analysis

➤ 𝗟𝗼𝘄 𝗟𝗲𝘃𝗲𝗹 𝗗𝗲𝘀𝗶𝗴𝗻 (𝗟𝗟𝗗)
 • What is Low Level Design or LLD
 • Data Structures and Algorithms for System Design
 • Event-Driven Architecture
 • Difference between Authentication and Authorization
 • What is API Gateway
 • What is Data Encryption?
 • Design Patterns
 • Code Optimization Techniques
 • Unit Testing
 • Integration Testing
 • CI/CD: Continuous Integration and Continuous Delivery
 • Introduction to Modularity and Interfaces In System Design
 • Data Partitioning Techniques
 • Class Diagrams | UML

➤ 𝗛𝗶𝗴𝗵 𝗟𝗲𝘃𝗲𝗹 𝗗𝗲𝘀𝗶𝗴𝗻 (𝗛𝗟𝗗)
 • What is High Level Design
 • Availability in System Design
 • Consistency in System Design
 • Reliability in System Design
 • CAP Theorem
 • Difference between Process and Thread
 • Difference between Concurrency and Parallelism
 • Load Balancer
 • Consistent Hashing
 • Content Delivery Network (CDN) in System Design
 • Caching in System Design
 • Cache Eviction Policies
 • Message Queues
 • Communication Protocols
 • Network Protocols and Proxies in System Design
 • Unified Modeling Language (UML)

➤ 𝗗𝗼 𝗧𝗵𝗲𝘀𝗲 𝗤𝘂𝗲𝘀𝘁𝗶𝗼𝗻𝘀
 • Design URL Shortening Service
 • Design Dropbox
 • Design Twitter
 • System Design Netflix - A Complete Architecture
 • System Design of Uber App - Uber System Architecture
 • Design Book My Show
 • Designing Facebook Messenger
 • Designing WhatsApp Messenger
 • Designing Instagram

Data Redundancy :
Data redundancy is when multiple copies of the same information are stored in more than one place at a time.A typical example of this is customer information
that is replicated across departments’ separate systems (e.g., finance, marketing, sales).
Data replication is the deliberate process of making multiple copies of data and storing them in different locations to improve accessibility. It encompasses 
the replication of transactions on an ongoing basis to allow users to share data between systems without any inconsistency.

Data Replication:
Data replication also known as database replication, is a method of copying data to ensure that all information stays 
identical in real-time between all data resources.

Partitioning
Split large tables into smaller, more manageable pieces to improve query performance and maintenance.
It is the process of splitting a database table into multiple logical units, or partitions, that are stored separately on disk.
eg. in table of employee, we can store emp_id 1 to 10,000 in table employee_partition_1 and empId 10,001 to 20,000 in table employee_partition_2.
There are several types of partitioning, including RANGE, LIST, and KEY. Above example is range one.
When data is written to the table, a partitioning function will be used by MySQL to decide which partition to store the data in. 
The value for one or more columns in a given row is used for this sorting process.

Sharding :https://blog.algomaster.io/p/scalability?open=false#%C2%A7shardingpartitioning
Sharding is a method for distributing a single dataset across multiple databases, which can then be stored on multiple 
machines. This allows for larger datasets to be split into smaller chunks and stored in multiple data nodes, 
increasing the total storage capacity of the system. Sharding is a form of scaling known as horizontal scaling or 
scale-out, as additional nodes are brought on to share the load.

Database indexes:
An index is a database structure that you can use to improve the performance of database activity. A database table can 
have one or more indexes associated with it.
An index is defined by a field expression that you specify when you create the index. Typically, the field expression 
is a single field name, like emp_id. An index created on the emp_id field, for example, contains a sorted list of 
the employee ID values in the table. Each value in the list is accompanied by references to the rows that contain 
that value.
A database driver can use indexes to find rows quickly. An index on the emp_id field, for example, greatly reduces the 
time that the driver spends searching for a particular employee ID value. Consider the following Where clause:
WHERE EMP_id = 'E10001'
Without an index, the server must search the entire database table to find those rows having an employee ID of E10001.
By using an index on the emp_id field, however, the server can quickly find those rows.

Proxy:
Forward proxy :
Operates between clients and external systems, protecting the client's identity and managing client-side requests
Forward proxies can hide the device's IP address by assigning one of its IP addresses
Reverse proxy
Operates between clients and servers, protecting server-side interests.Reverse proxies can manage load balancing and routing. 

Websocket :
WebSockets is a communication protocol providing full-duplex, bidirectional communication channels over a single, 
long-lived TCP connection. It enables real-time data exchange between a client (e.g., web browser) and a server with 
low overhead, reducing latency compared to traditional HTTP-based techniques like polling or long polling. WebSocket 
connections are established through a WebSocket handshake initiated over HTTP/HTTPS using the ws:// or wss:// URL schemes, 
then upgraded to the WebSocket protocol. Commonly used in applications like chat, gaming, IoT, and live updates. 
WebSockets supports both binary and text data formats.

API Gateway :
An API gateway accepts API requests from a client, processes them based on defined policies, directs them to the 
appropriate services, and combines the responses for a simplified user experience. Typically, it handles a request 
by invoking multiple microservices and aggregating the results. It can also translate between protocols in legacy 
deployments.
For microservices‑based applications, an API gateway acts as a single point of entry into the system. It sits in front 
of the microservices and simplifies both the client implementations and the microservices app by decoupling the 
complexity of an app from its clients.
In a microservices architecture, the API gateway is responsible for request routing, composition, and policy enforcement. 
It handles some requests by simply routing them to the appropriate backend service, and handles others by invoking 
multiple backend services and aggregating the results.
An API gateway might provide other capabilities for microservices such as authentication, authorization, monitoring, 
load balancing, and response handling, offloading implementation of non-functional requirements to the infrastructure 
layer and helping developers to focus on core business logic, speeding up app releases.

MQ: A message queue is a queue of messages sent between applications. It includes a sequence of work objects that are waiting to be processed.
RabbitMQ consists of:
1. producer — the client that creates a message
2. consumer — receives a message
3. queue — stores messages
3. exchange — enables to route messages and send them to queues
The system functions in the following way:
1. producer creates a message and sends it to an exchange
2. exchange receives a message and routes it to queues subscribed to it
3. consumer receives messages from those queues he/she is subscribed to
One should note that messages are filtered and routed depending on the type of exchange

Caching is a technique used to store and retrieve frequently accessed data or computations to speed up subsequent 
data requests. By storing data temporarily in a cache, systems can reduce the time and resources required to fetch
the same data from its original source, leading to improved performance and reduced latency.
Different types of caching:
Caching can be broadly categorized into two types: local caching and distributed caching.
Local caching refers to storing data on a single machine or within a single application. It’s commonly used in 
scenarios where data retrieval is limited to one machine or where the volume of data is relatively small. Examples 
of local caching include browser caches or application-level caches.
Distributed caching involves storing data across multiple machines or nodes, often in a network. This type of caching 
is essential for applications that need to scale across multiple servers or are distributed geographically. Distributed 
caching ensures that data is available close to where it’s needed, even if the original data source is remote or under 
heavy load.

ACID transaction:
Atomicity :Atomicity in ACID transactions guarantees that a transaction is treated as a single, indivisible unit of work. 
If any part of the transaction fails, the entire transaction must be rolled back, meaning that any changes made during 
the transaction are undone.
Consistency :Consistency ensures that the database remains in a valid state before and after the transaction.
Isolation :This property ensures that each transaction operates independently of other transactions, which means that a 
transaction’s effects should only become visible to other transactions after it has been committed. This property prevents 
interference and conflicts between concurrent transactions.
Durability :-
This characteristic makes sure that, even in a system failure, the changes made to the database during a transaction 
are irreversible. Any changes made after a transaction is committed must persist, even if the system is destroyed or 
loses power.

Latency & Throughput:
Latency determines the delay that a user experiences when they send or receive data from the network. 
Throughput determines the number of users that can access the network at the same time. 
A network with low throughput and high latency struggles to send and process high data volume, which results in congestion 
and poor application performance. In contrast, a network with high throughput and low latency is responsive and efficient.

To improve latency, you can shorten the propagation between the source and destination. You can improve throughput by 
increasing the overall network bandwidth.

What is fault tolerance?
Fault tolerance describes a system’s ability to handle errors and outages without any loss of functionality.
An example of a fault-tolerant multi-region architecture.
Fault tolerance implies zero service interruptions. If there is a failure somewhere the system will instantly 
switch to the backup solution and service will continue without interruption.
Fault tolerance implies zero service interruptions. If there is a failure somewhere the system will instantly switch
to the backup solution and service will continue without interruption.

The main difference between fault tolerance and fault resilience is that fault tolerance allows a system to continue 
functioning even when some components fail, while fault resilience allows a system to recover from failures quickly: 
Fault tolerance :A system is fault tolerant if it can continue to operate effectively even when there are faults. 
For example, a fault tolerant service might appear to have no downtime even if the machine it's running on crashes. 
Fault resilience :A system is fault resilient if it can recover from failures quickly and continue operating 
without significant downtime. Faults may be observed, but only in uncommitted data

High availability
A system that can minimize service interruptions by ensuring that systems are always accessible and operational. 
High availability uses techniques like load balancing and clustering to distribute tasks across multiple servers. 
High availability systems have a minimal allowed level of service interruption, such as a system with “five nines” 
availability that is down for approximately 5 minutes per year.

Distributed Tracing:
Distributed Tracing in Microservices explains how to monitor and track requests as they move through different services
in a microservices architecture. In microservices, a single user request might interact with multiple small services, 
making it hard to identify where issues occur. Distributed tracing provides a way to follow the path of a request, 
helping developers see the flow of data and pinpoint any problems.
