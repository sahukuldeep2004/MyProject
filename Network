DNS: Translates website names to IP address. DNS service works much like a phone directory. Services like Route53 help configure 
the domain and routing, and one needs to understand common types of resource records like A, CNAME, NS, MX, etc.
CDN: The content delivery network is a server between the origin and the client. It stores and delivers content to the end users, 
reducing latency and improving the system's overall performance.
PUB SUB: Publish-subscribe messaging works asynchronously, involving publishers, topics, subscribers, and messages. It helps to 
decouple the system, scalability, Durability, etc.
Load Balancer: Load balancer helps divide and divert traffic across the system. It helps drive the overall system Availability and Performance.
Distributed Caching: Caching servers store the data in memory and return it to the end users, improving the overall performance and
end-user experience. A fleet of servers works together to keep and serve the data in a distributed caching system, enhancing availability.
Observability: It's important to know what is happening in the system. How do we make the system easier to debug and fix? Observability 
helps the system to drive maintainability, resiliency, and reliability.
Unstructured Data Storage: Storing photos, videos, audio, and other unstructured data is essential when designing a system since these 
cannot be stored in traditional databases. One needs to create a highly available, consistent, reliable solution. and efficient.
Scaling Services: Scalability is an essential building block of any robust system. Understanding various scaling options and 
what options should be used is critical. From Serverless to ID generators, one must understand the multiple options and how to design them.
Distributed Search: Search is the core of many system designs. Understating how to build a search system and the core building blocks 
of a search system, including crawling and indexing, is essential.

Load balancing is the unsung hero of high-performance web applications.

1.] 𝐑𝐨𝐮𝐧𝐝 𝐑𝐨𝐛𝐢𝐧
➥ Distributes requests sequentially across a list of servers, like taking turns.
2.] 𝐋𝐞𝐚𝐬𝐭 𝐂𝐨𝐧𝐧𝐞𝐜𝐭𝐢𝐨𝐧𝐬
➥ Directs requests to the server with the fewest active connections.
3.] 𝐖𝐞𝐢𝐠𝐡𝐭𝐞𝐝 𝐑𝐨𝐮𝐧𝐝 𝐑𝐨𝐛𝐢𝐧
➥ Similar to Round Robin but assigns weights to servers based on their capacity, directing more traffic to more powerful servers.
4.] 𝐖𝐞𝐢𝐠𝐡𝐭𝐞𝐝 𝐋𝐞𝐚𝐬𝐭 𝐂𝐨𝐧𝐧𝐞𝐜𝐭𝐢𝐨𝐧𝐬
➥ Combines the benefits of Least Connections and Weighted Round Robin, considering both server load and capacity.
5.] 𝐈𝐏 𝐇𝐚𝐬𝐡
➥ Uses the client's IP address to consistently direct their requests to the same server.
6.] 𝐋𝐞𝐚𝐬𝐭 𝐑𝐞𝐬𝐩𝐨𝐧𝐬𝐞 𝐓𝐢𝐦𝐞
➥ Directs requests to the server with the quickest response time and the lowest number of active connections.
7.] 𝐑𝐚𝐧𝐝𝐨𝐦
➥ Assigns requests to servers randomly.
8.] 𝐋𝐞𝐚𝐬𝐭 𝐁𝐚𝐧𝐝𝐰𝐢𝐝𝐭𝐡
➥ Sends requests to the server consuming the least amount of network bandwidth.

ACID transactions are difficult to maintain in distributed systems due to factors such as network latency, consistency, availability, and scalability. To address these challenges, several solutions have been developed, including:

Two-phase commit: This protocol ensures that all nodes in a distributed system agree to commit a transaction before it is committed, ensuring data consistency and agreement on the transaction’s outcome.
Multi-Version Concurrency Control (MVCC): This technique manages data concurrency in a distributed system by allowing each transaction to access the appropriate data version, enabling multiple versions of the same data to coexist.
Replication: In a distributed system, replication involves keeping multiple copies of the same data on various nodes, reducing network latency and increasing availability.
Sharding: This process involves dividing data across multiple nodes in a distributed system, improving performance and scalability but increasing the complexity of maintaining data consistency.

Batch processing vs. stream processing: 7 Differences to know:

While batch processing is about processing large volumes of data at scheduled intervals, stream processing is all 
about handling data on-the-fly, in real time, or near-real-time. The best choice depends on the specific needs of 
a project or business requirement
